{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Zw7IdRBW-rc",
        "outputId": "f66f7e99-48d4-4680-eeb3-19313cab5c6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyDOE\n",
            "  Downloading pyDOE-0.3.8.zip (22 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyDOE) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyDOE) (1.7.3)\n",
            "Building wheels for collected packages: pyDOE\n",
            "  Building wheel for pyDOE (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyDOE: filename=pyDOE-0.3.8-py3-none-any.whl size=18184 sha256=466633d027f7fe37e578aec35893614ef04e4f82075fa9581d4aabd68da209ac\n",
            "  Stored in directory: /root/.cache/pip/wheels/83/ce/8a/87b25c685bfeca1872d13b8dc101e087a9c6e3fb5ebb47022a\n",
            "Successfully built pyDOE\n",
            "Installing collected packages: pyDOE\n",
            "Successfully installed pyDOE-0.3.8\n"
          ]
        }
      ],
      "source": [
        "#https://github.com/amitrajitbose/handwritten-digit-recognition/blob/master/handwritten_digit_recognition_CPU.ipynb\n",
        "#https://towardsdatascience.com/handwritten-digit-mnist-pytorch-977b5338e627\n",
        "!pip install pyDOE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9EULB6NHXGG7"
      },
      "outputs": [],
      "source": [
        "#imports\n",
        "# Import necessary packages\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "import os\n",
        "from google.colab import drive\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "\n",
        "\n",
        "import torch.autograd as autograd         # computation graph\n",
        "from torch import Tensor                  # tensor node in the computation graph\n",
        "import torch.nn as nn                     # neural networks\n",
        "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
        "\n",
        "import matplotlib.gridspec as gridspec\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import matplotlib.ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "#from pyDOE import lhs         #Latin Hypercube Sampling\n",
        "import scipy.io"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTIdxFcIhbBi"
      },
      "source": [
        "# MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IjOoCyqjXHaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429,
          "referenced_widgets": [
            "e2e8e1df4947410294cc1fc227701104",
            "75fa7013d7dc4b758fe7e0c454954f21",
            "5c14aad30d064e7b9897033b88de5969",
            "bd66441f58084426965e1d8c6146f8ca",
            "8c0fd7f2c9eb4b4ba02d4c30e3f284e0",
            "66c8b9ab4d854c5b921dde9fa4cf83ce",
            "e3c8ff45d7494d50a324c6df36b6ef92",
            "681033c19b024a2392c42dd426a313ca",
            "5b0fb4ca031449799d4f2b8b7efcb40f",
            "bfbf5b82c295477b939c7862a4cc7f2b",
            "e40dfcbd2722452d8e32ac876a8094f7",
            "d2f22ea4d6e54e16a15e389e12befee6",
            "91e1516b0a884191901aae447205df44",
            "4fb3a30bff524941b42d9dba02e7e2d5",
            "67307813e5ea4b8b96f5177d672bdfd0",
            "da2818d62e2a4500803ab78c693d8b68",
            "09db52987c664138bca7444a658e312e",
            "ac18764c015c46d8a1d8ac78feb51f3a",
            "76e1ac1c3ee748acbda4308b153dc181",
            "86294d4743504a23ad8a1535fc945d2a",
            "7a4e54e90ab54c9b949b47309e431bca",
            "3b13592dc6bf41d7b2e507c9e76f3578",
            "199b0ae7aa784693bcc45dcd35cdd88b",
            "2d0874f8443b4920b0ab54c977228c9c",
            "10a298c255d949388d28bc5532446843",
            "8332ffbc03204900a79e8f6da4b94197",
            "7acaad617e4743b0b82c615ba205ef11",
            "ad93606885264bd6a5288ae1c46c6d58",
            "b599c8b978a94170a5580a3305bfc4ee",
            "bccdd936de36419c96030a1c50706483",
            "a1e26d5f7d894f4bbc6c26f078a35842",
            "a7a8385eeb514443ac1a5c10816110ff",
            "c1d1226392ba48c3bbdad0b176778c37",
            "a9a149c5013c4afe9983c5f44b5fcd42",
            "e6c173d262834b2cb5b603fbb6c7884d",
            "c386f522ed1a4c239df09637e76793c6",
            "6a378cb8e16d40fc80f9440427372f93",
            "fc78ebfacf42423884c8b16fcc471035",
            "d8a676b7b5a641f88981a8feca167a47",
            "a788ed8ee53f425a9f0a53b2c5c2b9f0",
            "cd2f64891d3247799eda26333dbe1fba",
            "5e9a437837cf4ac9b348d6800eb8eb91",
            "3f3807f8433a4eb0aba9fd539763f2ff",
            "53b82a1c141a4aa08eb05a9cedf2cee8"
          ]
        },
        "outputId": "a47557ff-9934-448b-fa58-207da26c9bb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to drive/My Drive/mnist/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/9912422 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e2e8e1df4947410294cc1fc227701104"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting drive/My Drive/mnist/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz to drive/My Drive/mnist/MNIST_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to drive/My Drive/mnist/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/28881 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d2f22ea4d6e54e16a15e389e12befee6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting drive/My Drive/mnist/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz to drive/My Drive/mnist/MNIST_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to drive/My Drive/mnist/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1648877 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "199b0ae7aa784693bcc45dcd35cdd88b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting drive/My Drive/mnist/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz to drive/My Drive/mnist/MNIST_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to drive/My Drive/mnist/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/4542 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a9a149c5013c4afe9983c5f44b5fcd42"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting drive/My Drive/mnist/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to drive/My Drive/mnist/MNIST_data/MNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                              transforms.Normalize((0.5,), (0.5,)),\n",
        "                              ])\n",
        "\n",
        "# Download and load the training data\n",
        "trainset = datasets.MNIST('drive/My Drive/mnist/MNIST_data/', download=True, train=True, transform=transform)\n",
        "valset = datasets.MNIST('drive/My Drive/mnist/MNIST_data/', download=True, train=False, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True) # change batch size to 128 from 64\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZbYs3IkXSNy",
        "outputId": "d2adfe69-4a01-4ab8-952f-6663a0c8f599"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "938\n"
          ]
        }
      ],
      "source": [
        "#output test\n",
        "#print(len(list(trainloader)))\n",
        "#batch count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pauzau9nXhYT",
        "outputId": "ac9c1891-ce31-4a85-fa3a-ccd6e537c27c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (3): ReLU()\n",
            "  (4): Linear(in_features=64, out_features=10, bias=True)\n",
            "  (5): LogSoftmax(dim=1)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# define the MNIST model\n",
        "# Layer details for the neural network\n",
        "input_size = 784\n",
        "hidden_sizes = [128, 64] # [10, 10]\n",
        "output_size = 10\n",
        "\n",
        "# Build a feed-forward network\n",
        "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_sizes[1], output_size),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3peJcIIXvzR"
      },
      "outputs": [],
      "source": [
        "criterion = nn.NLLLoss()\n",
        "images, labels = next(iter(trainloader))\n",
        "images = images.view(images.shape[0], -1)\n",
        "\n",
        "logps = model(images)\n",
        "loss = criterion(logps, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVvYVHn6mC4W"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Optimizers require the parameters to optimize and a learning rate\n",
        "MNIST_optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pcutkro_xW-7"
      },
      "source": [
        "# PINN SETUP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXofRCVRxZaI"
      },
      "outputs": [],
      "source": [
        "#PINN model\n",
        "#TODO define c\n",
        "c = 1 #heuristic\n",
        "class PINN(nn.Module):\n",
        "  #https://github.com/omniscientoctopus/Physics-Informed-Neural-Networks/tree/main/PyTorch/Burgers'%20Equation\n",
        "    ##Neural Network\n",
        "    def __init__(self,layers):\n",
        "        super().__init__() #call __init__ from parent class \n",
        "        'activation function'\n",
        "        self.activation = nn.Tanh()\n",
        "        'loss function'\n",
        "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
        "        'Initialise neural network as a list using nn.Modulelist'  \n",
        "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)]) \n",
        "        self.iter = 0 #For the Optimizer\n",
        "        'Xavier Normal Initialization'\n",
        "        for i in range(len(layers)-1):\n",
        "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
        "            # set biases to zero\n",
        "            nn.init.zeros_(self.linears[i].bias.data)   \n",
        "    'foward pass'\n",
        "    def forward(self,x):\n",
        "        if torch.is_tensor(x) != True:         \n",
        "            x = torch.from_numpy(x)                \n",
        "        a = x.float()\n",
        "        for i in range(len(layers)-2):  \n",
        "            z = self.linears[i](a)              \n",
        "            a = self.activation(z)    \n",
        "        a = self.linears[-1](a)\n",
        "        return a\n",
        "    'Loss Functions'\n",
        "    #Loss BC\n",
        "    def lossBC(self,x_BC,y_BC):\n",
        "      loss_BC=self.loss_function(self.forward(x_BC),y_BC)\n",
        "    \n",
        "      return loss_BC\n",
        "    #Loss PDE\n",
        "    def lossPDE(self,x_PDE):\n",
        "      g=x_PDE.clone()\n",
        "     # g.requires_grad=True #Enable differentiation #TODO REVIEW\n",
        "      g.retain_grad()\n",
        "      f=self.forward(g)\n",
        "      f_x_t = autograd.grad(f,g,torch.ones([g.shape[0], 1]).to(device), retain_graph=True, create_graph=True)[0] #first derivative\n",
        "      f_xx_tt = autograd.grad(f_x_t,g,torch.ones(g.shape).to(device), create_graph=True)[0]#second derivative\n",
        "      f_t=f_x_t[:,[1]]# we select the 2nd element for t (the first one is x) (Remember the input X=[x,t]) \n",
        "      f_xx=f_xx_tt[:,[0]]# we select the 1st element for x (the second one is t) (Remember the input X=[x,t]) \n",
        "      f_x=f_x_t[:,[0]]\n",
        "      f= -f_t + f_x + f_xx - c\n",
        "      return self.loss_function(f,f_hat)\n",
        "\n",
        "    def loss(self,x_BC,y_BC,x_PDE):\n",
        "      loss_bc=self.lossBC(x_BC,y_BC)\n",
        "\n",
        "      loss_pde=self.lossPDE(x_PDE)\n",
        "      return loss_bc+loss_pde\n",
        "\n",
        "    #Optimizer              X_train_Nu,Y_train_Nu,X_train_Nf                   \n",
        "    def closure(self):\n",
        "      PINN_optimizer.zero_grad()  \n",
        "      loss = self.loss(X_train_Nu,Y_train_Nu,X_train_Nf)\n",
        "      loss.backward()      \n",
        "      self.iter += 1\n",
        "      if self.iter % 100 == 0:\n",
        "        loss2=self.lossBC(X_test,Y_test)\n",
        "        print(\"Training Error:\",loss.detach().cpu().numpy(),\"---Testing Error:\",loss2.detach().cpu().numpy())\n",
        "      return loss   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KyzwzwIn2nHi"
      },
      "outputs": [],
      "source": [
        "#learning params\n",
        "steps=1000\n",
        "lr=1e-3\n",
        "layers = np.array([2,32,32,1]) # hidden layers\n",
        "# To generate new data:\n",
        "#x_min=-1\n",
        "#x_max=1\n",
        "#t_min=0\n",
        "#t_max=1\n",
        "#total_points_x=200\n",
        "#total_points_t=100\n",
        "#Nu: Number of training points # Nf: Number of collocation points (Evaluate PDE)\n",
        "#Nu=100\n",
        "#Nf=10000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuUHrunHdO_p",
        "outputId": "3fbd42d1-ea90-48d1-bd0d-630be8a49438"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "# PINN training on device\n",
        "#Set default dtype to float32\n",
        "torch.set_default_dtype(torch.float)\n",
        "\n",
        "#PyTorch random number generator\n",
        "torch.manual_seed(1234)\n",
        "\n",
        "# Random number generators in other libraries\n",
        "np.random.seed(1234)\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(device)\n",
        "\n",
        "if device == 'cuda': \n",
        "    print(torch.cuda.get_device_name()) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ungA0lNzFMSm"
      },
      "outputs": [],
      "source": [
        "#compact PINN training method\n",
        "pinn_loss_graph = []\n",
        "def trainPINN(X_train,Y_train,collocation,act_loss):\n",
        "  for i in range(steps):\n",
        "    if i==0:\n",
        "      print(\"Training Loss-----Test Loss\")\n",
        "    loss = PINN_model.loss(X_train,Y_train,collocation)# use mean squared error\n",
        "    PINN_optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    PINN_optimizer.step()\n",
        "    if i%(steps/10)==0:\n",
        "      #with torch.no_grad():\n",
        "       # test_loss=PINN.lossBC(X_test,Y_test)\n",
        "      print(\"--------------------------PINN STEP--------------------------\")\n",
        "      print('#',i)\n",
        "      print('PINN SELF LOSS COMPUTATION:',loss.detach().cpu().numpy(),'---')#,test_loss.detach().cpu().numpy())\n",
        "      #print('PINN PREDICTION OF MNIST LOSS',PINN_model.forward(X_train))\n",
        "      print('MNIST GROUND TRUTH LOSS:', act_loss)\n",
        "      print('PINN AVG. PREDICTION OF MNIST LOSS:',torch.mean(PINN_model.forward(X_train)))\n",
        "      pinn_loss_graph.append(loss.detach().cpu().numpy())\n",
        "     "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D69C17SK3Etr"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xz-jWwFKmLrC",
        "outputId": "449da1fb-552a-4620-dad2-156a7c144139"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 1 - Training loss: 0.0048665298836063475\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 1.6700616 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.0048665298836063475\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.2062, grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([8192, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 3.31841e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.31087735822714213\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3123, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 67\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 68 - Training loss: 0.31514711522344335\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 0.00013730343 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.31514711522344335\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3419, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 3.5815865e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.31514711522344335\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3155, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 2.8062354e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.31514711522344335\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3151, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 2.6651828e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.31514711522344335\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3151, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 2.5301483e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.31514711522344335\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3151, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 2.4020198e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.31514711522344335\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3151, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 2.2814172e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.31514711522344335\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3151, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 2.1689332e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.31514711522344335\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3151, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 2.0650486e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.31514711522344335\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3151, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 1.9699742e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.31514711522344335\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3151, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 68\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 69 - Training loss: 0.31925359743236226\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 9.9197125e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.31925359743236226\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3325, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 1.866412e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.31925359743236226\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3193, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 1.7884826e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.31925359743236226\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3193, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 1.7214481e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.31925359743236226\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3193, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 1.6630879e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.31925359743236226\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3193, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 8.0893915e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.31925359743236226\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3190, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 1.601079e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.31925359743236226\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3193, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 1.5609924e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.31925359743236226\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3193, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 1.5274417e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.31925359743236226\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3193, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 1.7311436e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.31925359743236226\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3191, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 69\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 70 - Training loss: 0.3233308860742207\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 0.00010817923 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3233308860742207\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3484, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 1.7367735e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3233308860742207\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3233, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 1.661983e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3233308860742207\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3233, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 1.6106088e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3233308860742207\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3233, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 1.5675018e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3233308860742207\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3233, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 1.5316899e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3233308860742207\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3233, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 1.5022715e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3233308860742207\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3233, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 8.1322265e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3233308860742207\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3230, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 6.730262e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3233308860742207\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3252, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 2.3736811e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3233308860742207\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3201, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 70\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 71 - Training loss: 0.3274253205195673\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 9.960195e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3274253205195673\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3536, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 1.8709625e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3274253205195673\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3274, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 1.7458774e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3274253205195673\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3274, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 1.6799792e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3274253205195673\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3274, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 1.6247134e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3274253205195673\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3274, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 1.5787282e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3274253205195673\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3274, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 1.5408131e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3274253205195673\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3274, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 1.5098274e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3274253205195673\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3274, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 6.9246785e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3274253205195673\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3200, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 1.4988418e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3274253205195673\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3274, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 71\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 72 - Training loss: 0.331509339784\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 0.00010295429 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.331509339784\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3559, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 1.773733e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.331509339784\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3316, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 1.6926278e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.331509339784\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3315, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 1.6340807e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.331509339784\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3315, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 1.5859108e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.331509339784\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3315, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 1.5465675e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.331509339784\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3315, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 1.5147258e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.331509339784\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3315, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 1.7244263e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.331509339784\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3313, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 1.4927456e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.331509339784\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3315, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 7.482538e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.331509339784\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3231, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 72\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 73 - Training loss: 0.33548129392839443\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 9.8546465e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.33548129392839443\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3591, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 1.6200345e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.33548129392839443\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3355, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 1.5556147e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.33548129392839443\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3355, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 1.5242416e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.33548129392839443\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3355, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 1.4987561e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.33548129392839443\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3355, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 0.0001629051 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.33548129392839443\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3409, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 1.5276665e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.33548129392839443\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3355, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 1.4980919e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.33548129392839443\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3355, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 1.4752774e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.33548129392839443\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3355, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 3.6685764e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.33548129392839443\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3311, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 73\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 74 - Training loss: 0.339478364122956\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 9.60279e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.339478364122956\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3625, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 1.6183707e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.339478364122956\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3394, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 1.559701e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.339478364122956\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3395, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 1.5229895e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.339478364122956\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3395, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 1.4948051e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.339478364122956\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3395, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 1.4733116e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.339478364122956\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3395, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 3.170779e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.339478364122956\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3385, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 1.4903853e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.339478364122956\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3395, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 6.934402e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.339478364122956\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3481, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 1.490292e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.339478364122956\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3395, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 74\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 75 - Training loss: 0.3434115897363691\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 9.512557e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3434115897363691\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3683, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 4.8037814e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3434115897363691\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3431, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 4.212854e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3434115897363691\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3434, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 3.8168705e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3434115897363691\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3434, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 3.4640384e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3434115897363691\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3434, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 3.1516884e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3434115897363691\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3434, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 2.877241e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3434115897363691\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3434, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 2.6379107e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3434115897363691\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3434, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 2.4307992e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3434115897363691\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3434, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 2.253032e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3434115897363691\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3434, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 75\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 76 - Training loss: 0.34736169858782023\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 8.5829415e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.34736169858782023\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3608, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 1.9900613e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.34736169858782023\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3474, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 1.8773161e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.34736169858782023\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3474, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 1.7883588e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.34736169858782023\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3474, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 1.7144966e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.34736169858782023\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3474, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 1.6536017e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.34736169858782023\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3474, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 1.6037945e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.34736169858782023\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3474, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 1.5634153e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.34736169858782023\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3474, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 1.5308939e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.34736169858782023\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3474, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 1.5124522e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.34736169858782023\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3475, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 76\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 77 - Training loss: 0.35126423022386105\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 9.154284e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.35126423022386105\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3729, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 1.6476602e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.35126423022386105\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3512, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 1.580784e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.35126423022386105\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3513, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 1.5449052e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.35126423022386105\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3513, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 1.5164051e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.35126423022386105\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3513, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 1.4940002e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.35126423022386105\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3513, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 1.4765121e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.35126423022386105\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3513, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 3.9599927e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.35126423022386105\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3536, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 1.5065069e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.35126423022386105\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3512, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 4.33328e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.35126423022386105\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3531, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 77\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 78 - Training loss: 0.3552245870073721\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 8.351004e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3552245870073721\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3773, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 1.7105616e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3552245870073721\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3552, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 1.6253582e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3552245870073721\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3552, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 1.5724278e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3552245870073721\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3552, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 1.533173e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3552245870073721\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3552, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 0.00018006738 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3552245870073721\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3619, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 1.5806392e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3552245870073721\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3552, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 1.5340787e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3552245870073721\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3552, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 1.5020511e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3552245870073721\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3552, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 1.9476745e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3552245870073721\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3546, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 78\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 79 - Training loss: 0.35915494727681696\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 8.0366284e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.35915494727681696\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3813, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 1.7194623e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.35915494727681696\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3593, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 1.6213418e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.35915494727681696\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3592, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 1.563129e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.35915494727681696\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3592, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 1.5228726e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.35915494727681696\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3592, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 1.4949532e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.35915494727681696\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3592, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 1.4755767e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.35915494727681696\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3592, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 1.8326855e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.35915494727681696\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3596, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 1.503387e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.35915494727681696\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3592, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 4.0548875e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.35915494727681696\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3578, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 79\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 80 - Training loss: 0.3630539422858753\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 7.625122e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3630539422858753\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3846, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 1.7810654e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3630539422858753\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3629, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 1.4454148e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3630539422858753\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3631, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 1.4444955e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3630539422858753\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3631, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 1.4436781e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3630539422858753\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3631, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 1.4429114e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3630539422858753\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3631, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 1.4421953e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3630539422858753\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3631, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 1.4415463e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3630539422858753\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3631, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 1.4409417e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3630539422858753\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3631, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 1.4403945e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3630539422858753\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3631, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 80\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 81 - Training loss: 0.3668731918721311\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 7.6465214e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3668731918721311\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3739, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 1.4540279e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3668731918721311\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3668, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 1.4496155e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3668731918721311\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3669, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 1.4482936e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3668731918721311\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3669, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 1.4471382e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3668731918721311\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3669, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 1.4461353e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3668731918721311\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3669, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 1.4452772e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3668731918721311\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3669, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 1.4445484e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3668731918721311\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3669, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 1.4439281e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3668731918721311\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3669, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 1.4434347e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3668731918721311\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3669, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 81\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 82 - Training loss: 0.3706306757957442\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 7.4222204e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3706306757957442\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3869, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 1.5509264e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3706306757957442\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3705, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 1.5263645e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3706306757957442\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3706, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 1.5077169e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3706306757957442\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3706, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 1.4929175e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3706306757957442\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3706, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 1.4813135e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3706306757957442\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3706, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 1.4723411e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3706306757957442\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3706, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 1.4655208e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3706306757957442\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3706, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 1.5476236e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3706306757957442\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3708, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 1.4922796e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3706306757957442\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3706, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 82\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 83 - Training loss: 0.3744568893396016\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 6.6858265e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3744568893396016\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3960, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 1.7427695e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3744568893396016\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3744, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 1.6499162e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3744568893396016\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3745, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 1.5947851e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3744568893396016\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3745, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 1.5540169e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3744568893396016\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3745, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 1.5241453e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3744568893396016\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3745, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 1.5286083e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3744568893396016\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3743, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 1.5848816e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3744568893396016\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3746, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 1.5216057e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3744568893396016\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3745, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 1.499056e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3744568893396016\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3745, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 83\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 84 - Training loss: 0.37814349635069305\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 8.1264945e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.37814349635069305\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3957, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 1.5713438e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.37814349635069305\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3782, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 1.5275053e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.37814349635069305\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3781, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 1.5033853e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.37814349635069305\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3781, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 1.4873709e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.37814349635069305\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3781, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 3.2090746e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.37814349635069305\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3738, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 1.5164446e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.37814349635069305\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3781, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 0.00015073961 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.37814349635069305\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3687, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 1.5145222e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.37814349635069305\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3781, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 4.7068184e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.37814349635069305\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3833, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 84\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 85 - Training loss: 0.3819945064434873\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 6.678916e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3819945064434873\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4022, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 1.7410352e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3819945064434873\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3819, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 1.6212806e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3819945064434873\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3820, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 1.5606425e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3819945064434873\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3820, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 1.5231583e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3819945064434873\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3820, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 1.5000418e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3819945064434873\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3820, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 1.485859e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3819945064434873\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3820, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 1.8897393e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3819945064434873\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3816, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 1.5101622e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3819945064434873\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3820, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 5.9993604e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3819945064434873\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3827, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 85\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 86 - Training loss: 0.3858195777132567\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 5.5615208e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3858195777132567\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4052, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 2.3573634e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3858195777132567\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3847, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 1.5082563e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3858195777132567\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3858, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 1.5036701e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3858195777132567\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3858, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 1.4994138e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3858195777132567\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3858, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 1.495504e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3858195777132567\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3858, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 1.4919018e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3858195777132567\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3858, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 1.4886375e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3858195777132567\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3858, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 1.4856798e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3858195777132567\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3858, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 1.483041e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3858195777132567\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3858, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 86\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 87 - Training loss: 0.3894824684301673\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 5.6996258e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3894824684301673\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3927, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 1.492218e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3894824684301673\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3895, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 1.487823e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3894824684301673\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3895, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 1.4852052e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3894824684301673\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3895, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 1.4829818e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3894824684301673\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3895, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 1.4810739e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3894824684301673\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3895, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 1.4794605e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3894824684301673\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3895, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 1.4781185e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3894824684301673\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3895, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 1.4770224e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3894824684301673\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3895, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 1.4761312e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.3894824684301673\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3895, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 87\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 88 - Training loss: 0.39317612226075455\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 5.721391e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.39317612226075455\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4031, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 1.5088807e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.39317612226075455\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3932, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 1.4972243e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.39317612226075455\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3932, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 1.4921578e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.39317612226075455\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3932, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 1.4883093e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.39317612226075455\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3932, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 1.485486e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.39317612226075455\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3932, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 1.4834394e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.39317612226075455\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3932, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 6.5340144e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.39317612226075455\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3963, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 1.5215467e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.39317612226075455\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3931, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 1.5050574e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.39317612226075455\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3932, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 88\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 89 - Training loss: 0.39677411228863163\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 2.2116985e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.39677411228863163\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4105, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 1.6280492e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.39677411228863163\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3968, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 1.5704213e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.39677411228863163\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3968, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 1.5377159e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.39677411228863163\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3968, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 1.5170524e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.39677411228863163\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3968, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 1.749997e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.39677411228863163\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4002, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 1.5509213e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.39677411228863163\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3968, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 1.5226874e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.39677411228863163\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3968, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 1.7233232e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.39677411228863163\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3958, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 1.5273804e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.39677411228863163\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3968, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 89\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 90 - Training loss: 0.40046210609265226\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 2.4755465e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.40046210609265226\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4169, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 1.5529835e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.40046210609265226\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4005, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 1.5133728e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.40046210609265226\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4005, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 1.5059248e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.40046210609265226\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4005, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 1.5009247e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.40046210609265226\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4005, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 1.505804e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.40046210609265226\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4005, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 1.5657984e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.40046210609265226\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4004, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 1.521735e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.40046210609265226\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4005, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 1.5085956e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.40046210609265226\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4005, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 2.191684e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.40046210609265226\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.3998, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 90\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 91 - Training loss: 0.4040549350445713\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 4.5604327e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4040549350445713\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4215, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 1.6690705e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4040549350445713\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4039, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 1.5839055e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4040549350445713\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4041, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 1.5476397e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4040549350445713\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4041, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 1.5265491e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4040549350445713\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4041, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 1.5143838e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4040549350445713\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4041, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 1.661887e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4040549350445713\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4041, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 1.5450981e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4040549350445713\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4041, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 1.5221065e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4040549350445713\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4041, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 1.6025132e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4040549350445713\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4039, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 91\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 92 - Training loss: 0.407638925479165\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 4.781843e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.407638925479165\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4260, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 2.0718583e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.407638925479165\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4076, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 1.5322877e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.407638925479165\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4076, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 1.5274459e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.407638925479165\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4076, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 1.5231889e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.407638925479165\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4076, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 1.5194712e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.407638925479165\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4076, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 1.5162191e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.407638925479165\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4076, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 1.5134218e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.407638925479165\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4076, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 1.511069e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.407638925479165\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4076, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 1.5090882e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.407638925479165\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4076, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 92\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 93 - Training loss: 0.4111813001795364\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 5.302927e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4111813001795364\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4190, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 1.5306077e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4111813001795364\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4112, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 1.5234126e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4111813001795364\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4112, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 1.5195527e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4111813001795364\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4112, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 1.516509e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4111813001795364\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4112, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 1.5141374e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4111813001795364\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4112, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 1.5123306e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4111813001795364\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4112, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 1.5109708e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4111813001795364\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4112, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 1.5099532e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4111813001795364\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4112, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 3.3371323e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4111813001795364\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4122, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 93\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 94 - Training loss: 0.4145839460877213\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 4.4084587e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4145839460877213\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4276, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 1.6147624e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4145839460877213\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4146, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 1.5808372e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4145839460877213\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4146, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 1.5577417e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4145839460877213\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4146, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 1.5422266e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4145839460877213\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4146, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 1.5320375e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4145839460877213\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4146, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 1.989427e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4145839460877213\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4152, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 1.5448388e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4145839460877213\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4146, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 5.925352e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4145839460877213\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4079, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 1.5468938e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4145839460877213\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4145, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 94\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 95 - Training loss: 0.41801129678673327\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 3.9005805e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.41801129678673327\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4351, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 1.74406e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.41801129678673327\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4181, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 1.6595743e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.41801129678673327\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4180, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 1.606271e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.41801129678673327\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4180, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 1.5726137e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.41801129678673327\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4180, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 1.5518177e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.41801129678673327\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4180, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 1.5392646e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.41801129678673327\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4180, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 1.6357511e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.41801129678673327\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4181, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 1.5560357e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.41801129678673327\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4180, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 1.5407555e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.41801129678673327\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4180, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 95\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 96 - Training loss: 0.42137472995562847\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 4.3321194e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.42137472995562847\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4360, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 1.5940874e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.42137472995562847\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4214, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 1.5572061e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.42137472995562847\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4214, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 1.5437655e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.42137472995562847\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4214, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 4.7593944e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.42137472995562847\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4222, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 1.5616042e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.42137472995562847\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4214, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 1.5452855e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.42137472995562847\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4214, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 1.7853692e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.42137472995562847\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4212, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 1.5606337e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.42137472995562847\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4214, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 1.545243e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.42137472995562847\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4213, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 96\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 97 - Training loss: 0.42467546513848214\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 3.215385e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.42467546513848214\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4388, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 1.5852178e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.42467546513848214\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4247, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 1.5532618e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.42467546513848214\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4247, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 1.5447084e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.42467546513848214\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4247, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 1.5405551e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.42467546513848214\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4247, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 2.6330054e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.42467546513848214\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4246, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 1.5666108e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.42467546513848214\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4247, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 9.825229e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.42467546513848214\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4144, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 1.57361e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.42467546513848214\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4246, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 1.5531973e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.42467546513848214\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4246, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 97\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 98 - Training loss: 0.4280444470041596\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 3.2385047e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4280444470041596\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4427, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 1.7267538e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4280444470041596\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4276, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 1.5453473e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4280444470041596\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4280, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 1.5448554e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4280444470041596\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4280, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 1.5444673e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4280444470041596\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4280, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 1.5441382e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4280444470041596\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4280, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 1.5438673e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4280444470041596\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4280, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 1.5436591e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4280444470041596\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4280, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 1.6537562e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4280444470041596\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4281, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 1.5491224e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4280444470041596\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4280, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 98\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 99 - Training loss: 0.43136102151769057\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 4.337412e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.43136102151769057\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4362, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 1.5655799e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.43136102151769057\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4314, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 1.559399e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.43136102151769057\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4314, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 1.5568812e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.43136102151769057\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4314, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 1.5549638e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.43136102151769057\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4314, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 1.5535056e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.43136102151769057\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4314, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 1.55246e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.43136102151769057\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4314, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 1.5516989e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.43136102151769057\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4314, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 1.8242857e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.43136102151769057\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4291, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 1.5541007e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.43136102151769057\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4313, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 99\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 100 - Training loss: 0.43471602590353503\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 3.5630503e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.43471602590353503\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4439, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 1.6359214e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.43471602590353503\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4347, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 1.601949e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.43471602590353503\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4347, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 1.5841175e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.43471602590353503\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4347, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 1.573316e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.43471602590353503\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4347, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 1.958756e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.43471602590353503\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4336, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 1.6346926e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.43471602590353503\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4347, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 1.5989892e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.43471602590353503\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4347, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 1.9099666e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.43471602590353503\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4341, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 1.6524435e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.43471602590353503\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4347, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 100\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 101 - Training loss: 0.43801255114297116\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 3.1026426e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.43801255114297116\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4516, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 1.9197896e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.43801255114297116\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4379, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 1.7347656e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.43801255114297116\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4380, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 1.6522401e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.43801255114297116\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4380, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 1.6104482e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.43801255114297116\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4380, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 5.651824e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.43801255114297116\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4378, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 1.633878e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.43801255114297116\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4380, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 1.6024314e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.43801255114297116\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4380, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 4.8186776e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.43801255114297116\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4314, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 1.622048e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.43801255114297116\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4381, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 101\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 102 - Training loss: 0.4410961975675148\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 2.1757465e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4410961975675148\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4534, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 1.8637445e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4410961975675148\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4412, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 1.6742425e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4410961975675148\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4411, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 3.6865972e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4410961975675148\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4425, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 1.666394e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4410961975675148\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4411, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 2.1977214e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4410961975675148\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4414, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 3.458806e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4410961975675148\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4419, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 1.7203308e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4410961975675148\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4414, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 1.7102112e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4410961975675148\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4409, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 5.397336e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4410961975675148\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4419, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 102\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 103 - Training loss: 0.44451067671338634\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 3.019301e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.44451067671338634\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4591, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 1.8020048e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.44451067671338634\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4457, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 1.2317493e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.44451067671338634\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4445, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 1.161889e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.44451067671338634\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4445, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 1.0942542e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.44451067671338634\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4445, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 1.0284494e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.44451067671338634\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4445, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 9.645023e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.44451067671338634\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4445, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 9.025207e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.44451067671338634\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4445, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 8.425833e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.44451067671338634\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4445, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 7.847625e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.44451067671338634\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4445, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 103\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 104 - Training loss: 0.4476754019763678\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 4.076145e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4476754019763678\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4470, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 6.883114e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4476754019763678\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4477, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 6.3586394e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4476754019763678\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4477, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 5.861595e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4476754019763678\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4477, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 5.3928843e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4476754019763678\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4477, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 4.953576e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4476754019763678\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4477, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 4.544757e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4476754019763678\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4477, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 4.1669446e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4476754019763678\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4477, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 3.820441e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4476754019763678\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4477, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 3.505536e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4476754019763678\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4477, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 104\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 105 - Training loss: 0.45079431020374744\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 4.21863e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.45079431020374744\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4534, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 3.0526442e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.45079431020374744\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4508, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 2.8132886e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.45079431020374744\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4508, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 2.6051844e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.45079431020374744\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4508, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 2.425093e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.45079431020374744\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4508, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 2.2708455e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.45079431020374744\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4508, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 2.140107e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.45079431020374744\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4508, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 2.030467e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.45079431020374744\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4508, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 1.939523e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.45079431020374744\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4508, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 1.8649152e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.45079431020374744\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4508, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 105\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 106 - Training loss: 0.45400299827681423\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 4.792497e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.45400299827681423\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4625, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 2.1861076e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.45400299827681423\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4540, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 2.0392326e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.45400299827681423\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4540, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 1.9300353e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.45400299827681423\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4540, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 1.8446344e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.45400299827681423\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4540, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 1.7789577e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.45400299827681423\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4540, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 1.7293276e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.45400299827681423\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4540, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 1.6925861e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.45400299827681423\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4540, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 2.2215224e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.45400299827681423\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4538, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 1.7184152e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.45400299827681423\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4540, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 106\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 107 - Training loss: 0.4572759978552617\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 3.5760466e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4572759978552617\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4697, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 1.8235352e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4572759978552617\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4574, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 1.7460501e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4572759978552617\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4573, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 1.6996872e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4572759978552617\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4573, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 1.6682983e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4572759978552617\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4573, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 1.6476266e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4572759978552617\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4573, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 1.6344057e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4572759978552617\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4573, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 2.4625947e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4572759978552617\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4569, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 1.6261629e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4572759978552617\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4573, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 1.6215021e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4572759978552617\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4573, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 107\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 108 - Training loss: 0.46043023880102485\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 2.460465e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.46043023880102485\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4737, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 1.6309116e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.46043023880102485\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4604, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 3.9076695e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.46043023880102485\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4601, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 1.6251629e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.46043023880102485\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4604, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 1.623473e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.46043023880102485\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4604, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 3.233292e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.46043023880102485\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4548, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 1.6278531e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.46043023880102485\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4604, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 3.1546333e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.46043023880102485\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4621, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 1.6221621e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.46043023880102485\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4604, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 1.1488868e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.46043023880102485\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4612, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 108\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 109 - Training loss: 0.46354202675158535\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 2.645309e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.46354202675158535\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4774, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 1.7532524e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.46354202675158535\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4636, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 4.712495e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.46354202675158535\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4647, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 1.6303734e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.46354202675158535\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4636, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 1.6284436e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.46354202675158535\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4635, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 1.6284076e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.46354202675158535\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4635, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 1.8451685e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.46354202675158535\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4631, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 1.628754e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.46354202675158535\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4635, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 1.6322855e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.46354202675158535\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4637, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 1.2855361e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.46354202675158535\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4606, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 109\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 110 - Training loss: 0.46669844523675913\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 2.8806166e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.46669844523675913\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4784, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 1.6366096e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.46669844523675913\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4667, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 1.6351594e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.46669844523675913\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4667, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 1.6351022e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.46669844523675913\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4667, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 1.635069e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.46669844523675913\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4667, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 1.9295244e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.46669844523675913\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4663, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 1.634834e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.46669844523675913\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4667, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 4.4473905e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.46669844523675913\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4676, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 1.6380078e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.46669844523675913\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4667, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 4.0517803e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.46669844523675913\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4606, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 110\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 111 - Training loss: 0.4697390576161301\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 2.3707033e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4697390576161301\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4821, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 1.681169e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4697390576161301\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4697, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 1.6515653e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4697390576161301\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4697, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 1.6443839e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4697390576161301\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4697, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 1.6426452e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4697390576161301\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4698, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 1.6515831e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4697390576161301\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4699, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 1.6420296e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4697390576161301\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4697, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 3.100827e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4697390576161301\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4654, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 1.651421e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4697390576161301\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4698, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 1.9534687e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4697390576161301\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4692, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 111\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 112 - Training loss: 0.47279013423268984\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 5.308775e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.47279013423268984\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4849, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 5.2673627e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.47279013423268984\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4736, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 3.4228262e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.47279013423268984\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4728, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 2.486088e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.47279013423268984\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4728, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 2.0210418e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.47279013423268984\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4728, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 1.8090611e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.47279013423268984\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4728, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 1.7163919e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.47279013423268984\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4728, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 1.6768925e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.47279013423268984\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4728, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 1.660445e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.47279013423268984\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4728, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 1.6537961e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.47279013423268984\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4728, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 112\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 113 - Training loss: 0.47568922815546555\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 2.2403558e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.47568922815546555\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4814, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 1.6628899e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.47568922815546555\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4757, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 1.6591348e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.47568922815546555\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4757, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 1.6577706e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.47568922815546555\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4757, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 1.6572677e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.47568922815546555\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4757, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 1.6570941e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.47568922815546555\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4757, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 2.3088896e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.47568922815546555\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4751, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 1.656622e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.47568922815546555\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4757, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 1.6565302e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.47568922815546555\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4757, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 1.6565034e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.47568922815546555\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4757, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 113\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 114 - Training loss: 0.4784988365702029\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 2.2551505e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4784988365702029\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4897, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 1.6730439e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4784988365702029\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4785, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 1.6665672e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4784988365702029\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4785, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 1.6656779e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4784988365702029\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4785, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 1.7459868e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4784988365702029\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4787, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 1.6674323e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4784988365702029\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4785, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 3.6466897e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4784988365702029\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4805, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 1.6651497e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4784988365702029\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4785, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 1.6906511e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4784988365702029\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4787, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 1.6864832e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4784988365702029\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4783, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 114\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 115 - Training loss: 0.48130676055005367\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 2.1517562e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.48130676055005367\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4937, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 1.6800145e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.48130676055005367\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4813, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 1.6733367e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.48130676055005367\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4813, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 1.6730916e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.48130676055005367\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4813, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 2.1075914e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.48130676055005367\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4818, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 1.6757232e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.48130676055005367\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4813, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 4.0470563e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.48130676055005367\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4831, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 1.6829981e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.48130676055005367\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4812, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 1.6733264e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.48130676055005367\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4813, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 2.851235e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.48130676055005367\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4814, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 115\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 116 - Training loss: 0.4842385465402339\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 2.1514725e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4842385465402339\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4960, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 0.0010552396 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4842385465402339\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4869, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 0.000987541 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4842385465402339\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4842, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 0.0009515686 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4842385465402339\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4842, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 0.00092497835 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4842385465402339\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4842, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 0.00090469 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4842385465402339\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4842, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 0.0008878872 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4842385465402339\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4842, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 0.00087308703 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4842385465402339\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4842, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 0.0008595585 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4842385465402339\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4842, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 0.00084690127 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4842385465402339\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4842, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 116\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 117 - Training loss: 0.48701294780031706\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 0.00084477523 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.48701294780031706\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4859, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 0.0008236177 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.48701294780031706\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4870, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 0.0008124729 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.48701294780031706\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4870, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 0.00080158166 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.48701294780031706\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4870, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 0.00079085847 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.48701294780031706\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4870, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 0.00078022084 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.48701294780031706\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4870, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 0.00076959096 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.48701294780031706\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4870, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 0.0007588898 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.48701294780031706\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4870, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 0.0007480345 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.48701294780031706\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4870, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 0.0007369291 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.48701294780031706\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4870, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 117\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 118 - Training loss: 0.4898893177382219\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 0.0007391982 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4898893177382219\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4897, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 0.00071442017 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4898893177382219\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4899, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 0.000701923 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4898893177382219\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4899, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 0.00068850955 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4898893177382219\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4899, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 0.00067382725 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4898893177382219\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4899, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 0.00065734866 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4898893177382219\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4899, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 0.0006382789 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4898893177382219\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4899, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 0.00061553443 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4898893177382219\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4899, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 0.00058794033 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4898893177382219\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4898, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 0.00055432745 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4898893177382219\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4898, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 118\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 119 - Training loss: 0.4927723951685403\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 0.0005310116 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4927723951685403\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4976, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 0.0004632068 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4927723951685403\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4927, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 0.0003979541 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4927723951685403\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4927, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 0.00033308382 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4927723951685403\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4939, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 0.0002861894 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4927723951685403\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4984, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 0.00020664468 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4927723951685403\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4926, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 0.00023086785 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4927723951685403\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4940, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 0.0001219673 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4927723951685403\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4927, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 9.481246e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4927723951685403\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4927, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 7.469847e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.4927723951685403\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4927, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 119\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 120 - Training loss: 0.495573270041297\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 9.422151e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.495573270041297\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5090, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 4.7664234e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.495573270041297\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4956, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 3.8177594e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.495573270041297\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4955, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 3.0474053e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.495573270041297\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4956, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 2.4304189e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.495573270041297\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4956, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 1.9483328e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.495573270041297\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4956, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 4.874836e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.495573270041297\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4886, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 1.345113e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.495573270041297\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4957, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 1.1497182e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.495573270041297\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4954, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 1.0793689e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.495573270041297\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4953, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 120\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 121 - Training loss: 0.49831703781827424\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 9.326483e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.49831703781827424\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5180, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 9.823615e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.49831703781827424\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4983, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 9.037381e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.49831703781827424\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4983, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 8.402889e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.49831703781827424\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4983, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 7.843784e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.49831703781827424\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4983, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 8.373589e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.49831703781827424\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4978, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 7.460211e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.49831703781827424\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4983, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 1.8561073e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.49831703781827424\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5003, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 7.1382183e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.49831703781827424\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.4983, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 1.6579894e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.49831703781827424\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5022, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 121\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 122 - Training loss: 0.5009102722220837\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 9.9188954e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5009102722220837\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5195, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 7.613424e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5009102722220837\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5009, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 7.060642e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5009102722220837\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5009, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 6.616163e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5009102722220837\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5009, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 6.2104714e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5009102722220837\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5009, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 7.002417e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5009102722220837\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5011, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 6.2568465e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5009102722220837\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5009, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 7.400648e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5009102722220837\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5021, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 6.2326994e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5009102722220837\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5011, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 5.744042e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5009102722220837\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5009, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 122\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 123 - Training loss: 0.5035556854723867\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 9.03411e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5035556854723867\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5203, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 6.402028e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5035556854723867\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5036, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 5.908595e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5035556854723867\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5036, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 5.5077926e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5035556854723867\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5036, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 8.911991e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5035556854723867\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5048, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 5.543683e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5035556854723867\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5035, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 1.5286354e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5035556854723867\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5006, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 5.4595534e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5035556854723867\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5034, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 5.223379e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5035556854723867\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5032, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 5.3978893e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5035556854723867\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5034, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 123\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 124 - Training loss: 0.506058155854882\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 0.00010802745 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.506058155854882\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5248, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 6.250511e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.506058155854882\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5062, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 5.6420413e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.506058155854882\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5061, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 5.225406e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.506058155854882\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5061, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 4.8694974e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.506058155854882\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5061, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 4.567178e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.506058155854882\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5062, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 5.087148e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.506058155854882\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5063, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 4.711363e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.506058155854882\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5061, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 2.2581893e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.506058155854882\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5163, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 4.979277e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.506058155854882\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5062, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 124\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 125 - Training loss: 0.5087141075622298\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 9.9800265e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5087141075622298\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5260, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 5.576467e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5087141075622298\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5087, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 5.0506005e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5087141075622298\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5087, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 4.631194e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5087141075622298\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5087, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 4.2672636e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5087141075622298\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5087, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 5.9043796e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5087141075622298\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5082, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 4.712885e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5087141075622298\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5087, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 4.3009895e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5087141075622298\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5087, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 1.1543154e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5087141075622298\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5053, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 4.661829e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5087141075622298\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5087, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 125\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 126 - Training loss: 0.5113509036838881\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 9.9115e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5113509036838881\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5284, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 5.6152603e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5113509036838881\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5113, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 4.921618e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5113509036838881\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5113, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 4.3923637e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5113509036838881\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5113, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 3.9764027e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5113509036838881\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5112, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 4.701228e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5113509036838881\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5113, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 4.1249514e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5113509036838881\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5113, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 1.1977345e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5113509036838881\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5091, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 4.4211783e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5113509036838881\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5113, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 5.458369e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5113509036838881\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5103, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 126\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 127 - Training loss: 0.5138155946345218\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 8.825978e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5138155946345218\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5279, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 5.1216557e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5138155946345218\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5137, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 4.26644e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5138155946345218\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5138, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 3.6216632e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5138155946345218\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5162, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 4.6861815e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5138155946345218\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5138, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 3.9625875e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5138155946345218\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5138, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 5.550877e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5138155946345218\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5145, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 4.433305e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5138155946345218\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5138, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 2.4520346e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5138155946345218\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5175, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 5.0258577e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5138155946345218\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5137, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 127\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 128 - Training loss: 0.5164823305886438\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 9.3571114e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5164823305886438\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5321, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 5.2439455e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5164823305886438\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5165, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 4.494275e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5164823305886438\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5165, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 3.927281e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5164823305886438\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5165, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 6.2013987e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5164823305886438\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5169, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 4.612082e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5164823305886438\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5165, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 3.9231722e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5164823305886438\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5165, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 5.297181e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5164823305886438\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5162, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 4.212704e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5164823305886438\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5165, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 2.0025178e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5164823305886438\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5166, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 128\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 129 - Training loss: 0.518976374221509\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 8.694783e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.518976374221509\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5332, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 4.806746e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.518976374221509\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5190, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 4.109714e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.518976374221509\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5190, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 2.373602e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.518976374221509\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5211, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 4.6955747e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.518976374221509\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5190, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 3.934555e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.518976374221509\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5190, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 6.469256e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.518976374221509\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5194, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 4.2941397e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.518976374221509\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5190, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 0.0002086617 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.518976374221509\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5190, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 4.7309086e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.518976374221509\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5190, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 129\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 130 - Training loss: 0.5215668690992571\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 8.677711e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5215668690992571\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5368, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 5.4166767e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5215668690992571\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5214, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 4.633116e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5215668690992571\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5216, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 4.084935e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5215668690992571\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5216, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 8.741119e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5215668690992571\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5216, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 4.4908356e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5215668690992571\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5216, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 6.0781763e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5215668690992571\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5228, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 4.7680633e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5215668690992571\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5215, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 3.9823412e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5215668690992571\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5216, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 5.95598e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5215668690992571\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5205, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 130\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 131 - Training loss: 0.5240052318267985\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 8.097393e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5240052318267985\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5384, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 4.839006e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5240052318267985\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5240, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 4.1999842e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5240052318267985\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5240, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 0.0008376135 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5240052318267985\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5041, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 5.1287893e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5240052318267985\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5240, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 4.193649e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5240052318267985\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5240, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 8.203341e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5240052318267985\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5227, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 4.2519478e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5240052318267985\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5240, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 0.0006024548 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5240052318267985\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5394, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 4.2766887e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5240052318267985\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5240, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 131\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 132 - Training loss: 0.5264131306076864\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 0.00023665835 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5264131306076864\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5277, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 4.258156e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5264131306076864\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5264, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 1.4730712e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5264131306076864\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5289, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 4.380442e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5264131306076864\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5265, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 3.7344016e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5264131306076864\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5265, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 4.281059e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5264131306076864\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5267, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 1.1308468e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5264131306076864\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5244, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 4.0778123e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5264131306076864\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5265, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 1.690448e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5264131306076864\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5216, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 3.778905e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5264131306076864\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5264, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 132\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 133 - Training loss: 0.5289317570261355\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 6.4487445e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5289317570261355\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5429, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 4.4262147e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5289317570261355\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5288, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 3.8917888e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5289317570261355\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5289, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 5.0365607e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5289317570261355\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5286, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 3.7934647e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5289317570261355\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5289, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 4.7321973e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5289317570261355\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5293, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 5.8289233e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5289317570261355\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5278, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 3.958034e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5289317570261355\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5291, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 4.8547636e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5289317570261355\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5296, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 3.9438964e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5289317570261355\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5306, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 133\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 134 - Training loss: 0.5313730921064105\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 8.910387e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5313730921064105\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5430, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 4.4706608e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5313730921064105\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5313, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 2.3579787e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5313730921064105\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5352, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 3.98395e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5313730921064105\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5313, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 8.215077e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5313730921064105\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5312, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 9.2359114e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5313730921064105\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5284, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 6.111578e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5313730921064105\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5302, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 4.1035682e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5313730921064105\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5310, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 3.80776e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5313730921064105\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5311, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 3.881342e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5313730921064105\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5311, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 134\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 135 - Training loss: 0.5339601695664656\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 9.1925685e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5339601695664656\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5500, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 5.9553645e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5339601695664656\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5338, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 4.463147e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5339601695664656\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5340, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 3.738524e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5339601695664656\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5340, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 4.3265663e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5339601695664656\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5341, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 1.1434985e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5339601695664656\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5362, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 3.863684e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5339601695664656\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5339, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 5.1596717e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5339601695664656\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5342, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 9.622348e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5339601695664656\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5321, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 2.2219938e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5339601695664656\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5331, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 135\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 136 - Training loss: 0.5362195350976386\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 7.114652e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5362195350976386\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5506, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 4.7162553e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5362195350976386\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5362, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 3.906968e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5362195350976386\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5362, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 4.4788558e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5362195350976386\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5360, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 7.825033e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5362195350976386\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5366, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 4.7223375e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5362195350976386\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5364, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 4.069403e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5362195350976386\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5362, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 4.31121e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5362195350976386\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5356, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 5.971356e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5362195350976386\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5370, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 6.8433933e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5362195350976386\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5375, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 136\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 137 - Training loss: 0.5385301519812805\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 6.4527165e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5385301519812805\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5529, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 4.6302507e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5385301519812805\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5385, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 3.7639606e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5385301519812805\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5385, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 4.6326177e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5385301519812805\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5395, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 7.862268e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5385301519812805\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5377, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 1.6487356e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5385301519812805\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5400, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 5.6484423e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5385301519812805\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5380, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 3.929597e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5385301519812805\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5382, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 3.9747306e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5385301519812805\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5378, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 8.582306e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5385301519812805\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5403, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 137\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 138 - Training loss: 0.5407928215669416\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 3.9216604e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5407928215669416\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5534, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 3.7848026e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5407928215669416\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5408, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 3.526673e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5407928215669416\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5442, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 9.7771e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5407928215669416\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5475, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 1.8089315e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5407928215669416\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5433, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 9.146097e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5407928215669416\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5393, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 1.0533811e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5407928215669416\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5383, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 1.2287408e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5407928215669416\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5431, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 4.4959816e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5407928215669416\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5416, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 3.981711e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5407928215669416\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5359, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 138\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 139 - Training loss: 0.5429207912640277\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 8.246276e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5429207912640277\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5489, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 1.216686e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5429207912640277\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5430, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 7.6249326e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5429207912640277\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5416, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 3.7314217e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5429207912640277\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5426, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 4.292916e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5429207912640277\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5420, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 2.104833e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5429207912640277\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5399, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 1.1537886e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5429207912640277\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5454, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 1.0565986e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5429207912640277\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5453, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 0.0001689932 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5429207912640277\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5381, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 3.2089902e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5429207912640277\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5427, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 139\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 140 - Training loss: 0.5451541755245184\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 9.6321295e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5451541755245184\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5601, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 3.537434e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5451541755245184\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5452, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 2.9281691e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5451541755245184\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5452, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 3.0619365e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5451541755245184\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5454, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 4.2370075e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5451541755245184\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5460, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 4.4442304e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5451541755245184\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5437, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 1.0578959e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5451541755245184\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5431, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 9.2882765e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5451541755245184\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5474, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 1.8782142e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5451541755245184\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5505, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 1.382799e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5451541755245184\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5423, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 140\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 141 - Training loss: 0.5472677941007147\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 5.104726e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5472677941007147\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5587, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 2.7998349e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5472677941007147\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5472, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 2.9837365e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5472677941007147\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5468, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 8.10828e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5472677941007147\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5455, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 2.8432574e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5472677941007147\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5437, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 3.8994176e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5472677941007147\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5481, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 7.1591585e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5472677941007147\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5453, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 9.378278e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5472677941007147\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5412, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 1.6885011e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5472677941007147\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5502, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 3.4210003e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5472677941007147\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5427, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 141\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 142 - Training loss: 0.5494272401337938\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 1.6743033e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5494272401337938\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5600, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 2.4612066e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5494272401337938\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5489, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 2.0100458e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5494272401337938\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5495, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 1.9914032e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5494272401337938\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5494, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 1.9638435e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5494272401337938\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5494, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 2.6408031e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5494272401337938\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5496, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 2.0577536e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5494272401337938\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5494, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 6.865773e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5494272401337938\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5460, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 2.490873e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5494272401337938\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5494, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 2.154836e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5494272401337938\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5494, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 142\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 143 - Training loss: 0.551725258196849\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 0.0001456428 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.551725258196849\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5569, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 2.723085e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.551725258196849\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5517, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 2.2331847e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.551725258196849\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5517, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 8.462503e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.551725258196849\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5521, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 3.1126922e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.551725258196849\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5517, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 2.3591024e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.551725258196849\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5517, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 6.049766e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.551725258196849\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5518, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 2.8351733e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.551725258196849\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5517, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 9.5471696e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.551725258196849\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5610, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 4.07234e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.551725258196849\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5518, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 143\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 144 - Training loss: 0.5538791113062453\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 4.021135e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5538791113062453\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5633, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 4.694425e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5538791113062453\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5538, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 2.817224e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5538791113062453\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5539, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 9.973631e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5538791113062453\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5534, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 3.276531e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5538791113062453\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5539, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 6.565961e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5538791113062453\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5632, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 3.656424e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5538791113062453\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5539, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 1.9106232e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5538791113062453\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5513, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 3.7641394e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5538791113062453\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5538, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 1.0026506e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5538791113062453\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5556, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 144\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 145 - Training loss: 0.5560040612464775\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 3.2274475e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5560040612464775\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5649, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 3.0014787e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5560040612464775\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5560, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 5.389674e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5560040612464775\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5548, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 2.7987696e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5560040612464775\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5560, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 3.979586e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5560040612464775\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5561, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 1.7860559e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5560040612464775\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5584, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 3.1484205e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5560040612464775\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5560, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 6.7155484e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5560040612464775\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5552, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 2.631527e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5560040612464775\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5560, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 3.2561948e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5560040612464775\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5560, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 145\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 146 - Training loss: 0.5582297190165977\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 4.3651828e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5582297190165977\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5696, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 3.0840165e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5582297190165977\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5582, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 1.5873984e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5582297190165977\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5587, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 2.5957877e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5582297190165977\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5582, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 2.8750276e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5582297190165977\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5583, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 4.4739745e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5582297190165977\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5589, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 6.386357e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5582297190165977\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5594, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 5.2899095e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5582297190165977\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5567, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 1.0720484e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5582297190165977\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5598, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 4.278306e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5582297190165977\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5532, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 146\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 147 - Training loss: 0.5603554903317108\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 2.7524398e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5603554903317108\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5717, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 2.7575388e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5603554903317108\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5603, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 4.2556426e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5603554903317108\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5593, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 2.571479e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5603554903317108\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5607, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 3.5750904e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5603554903317108\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5596, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 1.870016e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5603554903317108\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5613, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 6.260674e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5603554903317108\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5533, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 2.4876747e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5603554903317108\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5604, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 2.4988603e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5603554903317108\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5604, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 8.628707e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5603554903317108\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5624, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 147\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 148 - Training loss: 0.5624760685444895\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 4.6309106e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5624760685444895\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5752, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 3.438799e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5624760685444895\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5605, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 2.4231126e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5624760685444895\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5625, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 2.3082189e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5624760685444895\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5625, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 2.2642744e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5624760685444895\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5625, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 2.2467339e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5624760685444895\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5625, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 2.302742e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5624760685444895\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5624, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 3.0692402e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5624760685444895\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5620, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 2.477158e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5624760685444895\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5629, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 2.99881e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5624760685444895\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5621, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 148\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 149 - Training loss: 0.5646301168622747\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 1.2332097e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5646301168622747\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5733, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 2.583829e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5646301168622747\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5647, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 3.4880563e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5646301168622747\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5660, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 7.4543786e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5646301168622747\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5667, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 7.4814284e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5646301168622747\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5629, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 3.774359e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5646301168622747\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5636, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 3.3905098e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5646301168622747\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5654, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 2.5706443e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5646301168622747\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5646, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 5.4550574e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5646301168622747\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5663, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 3.1427855e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5646301168622747\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5635, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 149\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 150 - Training loss: 0.5665296476278732\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 7.994434e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5665296476278732\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5818, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 3.5927803e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5665296476278732\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5673, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 5.5594523e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5665296476278732\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5677, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 8.528299e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5665296476278732\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5649, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 2.684481e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5665296476278732\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5660, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 3.226367e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5665296476278732\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5657, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 2.4983347e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5665296476278732\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5617, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 2.2385766e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5665296476278732\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5644, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 2.719736e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5665296476278732\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5669, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 1.1774218e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5665296476278732\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5639, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 150\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 151 - Training loss: 0.568534746225963\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 2.8018654e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.568534746225963\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5795, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 2.4340438e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.568534746225963\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5684, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 2.3641576e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.568534746225963\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5685, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 2.4455805e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.568534746225963\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5687, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 4.0094938e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.568534746225963\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5696, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 2.7313452e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.568534746225963\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5644, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 5.9416576e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.568534746225963\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5763, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 1.6465716e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.568534746225963\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5657, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 7.308131e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.568534746225963\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5666, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 4.0091677e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.568534746225963\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5683, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 151\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 152 - Training loss: 0.5706216748843569\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 4.684477e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5706216748843569\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5819, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 2.58708e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5706216748843569\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5701, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 2.3252007e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5706216748843569\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5706, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 2.559608e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5706216748843569\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5703, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 1.793565e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5706216748843569\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5671, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 2.4091942e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5706216748843569\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5724, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 1.0213627e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5706216748843569\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5676, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 9.997324e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5706216748843569\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5677, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 1.6511603e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5706216748843569\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5684, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 2.8767042e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5706216748843569\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5703, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 152\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 153 - Training loss: 0.5724836687035144\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 5.3932845e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5724836687035144\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5778, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 2.4922294e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5724836687035144\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5723, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 2.3234538e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5724836687035144\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5725, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 7.825037e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5724836687035144\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5736, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 2.4937956e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5724836687035144\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5721, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 2.4803953e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5724836687035144\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5728, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 5.1606435e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5724836687035144\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5742, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 2.2140997e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5724836687035144\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5752, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 9.505009e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5724836687035144\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5708, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 8.03093e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5724836687035144\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5647, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 153\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 154 - Training loss: 0.5745335178080399\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 8.633022e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5745335178080399\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5823, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 0.00082652434 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5745335178080399\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5722, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 0.0006841883 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5745335178080399\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5745, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 0.0006196089 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5745335178080399\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5746, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 0.00048239084 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5745335178080399\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5745, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 0.00046310364 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5745335178080399\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5745, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 0.0004419673 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5745335178080399\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5745, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 0.00041507187 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5745335178080399\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5745, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 0.00036126893 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5745335178080399\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5746, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 0.00030902924 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5745335178080399\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5745, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 154\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 155 - Training loss: 0.5764412334732918\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 0.00028674243 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5764412334732918\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5811, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 0.0002362061 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5764412334732918\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5764, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 0.00020005522 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5764412334732918\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5764, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 0.00016451029 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5764412334732918\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5764, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 0.00013034845 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5764412334732918\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5764, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 9.795333e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5764412334732918\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5764, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 0.00021003504 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5764412334732918\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5879, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 5.5888057e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5764412334732918\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5764, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 5.059541e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5764412334732918\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5801, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 3.1994612e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5764412334732918\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5764, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 155\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 156 - Training loss: 0.5782845124507001\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 6.9215435e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5782845124507001\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5864, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 2.3254446e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5782845124507001\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5783, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 4.0544182e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5782845124507001\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5807, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 1.9659505e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5782845124507001\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5783, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 1.5656005e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5782845124507001\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5783, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 4.0346153e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5782845124507001\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5761, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 1.4186131e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5782845124507001\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5783, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 1.156738e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5782845124507001\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5783, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 1.4169968e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5782845124507001\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5789, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 1.08551785e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5782845124507001\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5783, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 156\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 157 - Training loss: 0.580379813973075\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 0.000102363294 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.580379813973075\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5826, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 1.0299458e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.580379813973075\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5804, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 9.047924e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.580379813973075\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5808, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 1.0632222e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.580379813973075\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5805, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 8.632779e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.580379813973075\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5804, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 1.4623896e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.580379813973075\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5756, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 9.443003e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.580379813973075\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5804, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 7.825272e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.580379813973075\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5804, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 800\n",
            "PINN SELF LOSS COMPUTATION: 3.4179444e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.580379813973075\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5817, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 900\n",
            "PINN SELF LOSS COMPUTATION: 8.5290285e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.580379813973075\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5804, grad_fn=<MeanBackward0>)\n",
            "--------------------------SAVED PINN CHECKPOINT--------------------------\n",
            "Checkpoint # 157\n",
            "--------------------------MNIST TRAINING ITERATION--------------------------\n",
            "Iteration 158 - Training loss: 0.5822946675804886\n",
            "Training Loss-----Test Loss\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 0\n",
            "PINN SELF LOSS COMPUTATION: 5.322862e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5822946675804886\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5920, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 100\n",
            "PINN SELF LOSS COMPUTATION: 9.781625e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5822946675804886\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5821, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 200\n",
            "PINN SELF LOSS COMPUTATION: 8.031035e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5822946675804886\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5823, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 300\n",
            "PINN SELF LOSS COMPUTATION: 6.72047e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5822946675804886\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5823, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 400\n",
            "PINN SELF LOSS COMPUTATION: 1.2208349e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5822946675804886\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5825, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 500\n",
            "PINN SELF LOSS COMPUTATION: 7.532177e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5822946675804886\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5823, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 600\n",
            "PINN SELF LOSS COMPUTATION: 6.3431844e-06 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5822946675804886\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5823, grad_fn=<MeanBackward0>)\n",
            "--------------------------PINN STEP--------------------------\n",
            "# 700\n",
            "PINN SELF LOSS COMPUTATION: 1.0112732e-05 ---\n",
            "MNIST GROUND TRUTH LOSS: 0.5822946675804886\n",
            "PINN AVG. PREDICTION OF MNIST LOSS: tensor(0.5822, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ],
      "source": [
        "#MNIST training\n",
        "MNIST_optimizer = optim.SGD(model.parameters(), lr=0.003, momentum=0.9)\n",
        "time0 = time()\n",
        "epochs = 1\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    n=0\n",
        "    weight_train = [] # all weights, used for collocation\n",
        "    collocation = []\n",
        "    iter_weights = [] # store 8192 weights per iteration\n",
        "    idx_mat = [] # zeroes mat + n\n",
        "    iter_loss = 0\n",
        "    #idx=np.random.choice(X_train.shape[0],Nu,replace=False) # train\n",
        "    for images, labels in trainloader:\n",
        "        n+=1\n",
        "        # Flatten MNIST images into a 784 long vector\n",
        "        images = images.view(images.shape[0], -1)\n",
        "    \n",
        "        # Training pass\n",
        "        MNIST_optimizer.zero_grad()\n",
        "        \n",
        "        output = model(images)\n",
        "        loss = criterion(output, labels)\n",
        "        \n",
        "        #backprop\n",
        "        loss.backward()\n",
        "        \n",
        "        #update weights\n",
        "        MNIST_optimizer.step()\n",
        "       \n",
        "        running_loss += loss.item()\n",
        "        print('--------------------------MNIST TRAINING ITERATION--------------------------')\n",
        "        print('Iteration {} - Training loss: {}'.format(n,running_loss/len(trainloader)))\n",
        "        #print('weight mat', model[2].weight[0])\n",
        "        \n",
        "        # Collect data for PINN\n",
        "        iter_weights.append(model[2].weight)\n",
        "        idx_mat = torch.zeros((8192,1)) + n\n",
        "\n",
        "        #print('weight mat',torch.flatten(model[2].weight).unsqueeze(1))\n",
        "        #print('idx_mat',idx_mat)\n",
        "\n",
        "        weight_train = torch.hstack(( (torch.flatten(model[2].weight).unsqueeze(1)), idx_mat))\n",
        "        iter_loss = running_loss/len(trainloader)\n",
        "        f_hat = torch.zeros(weight_train.shape[0],1)\n",
        "\n",
        "        #print('weight mat',torch.flatten(model[2].weight).shape())\n",
        "        #print('idx_mat',idx_mat.shape())\n",
        "\n",
        "        weight_train=weight_train.float().to(device)#Training Points (BC)\n",
        "        iter_loss=torch.Tensor([iter_loss]).float().to(device)#Training Points (BC)\n",
        "        weight_train=weight_train.float().to(device)#Collocation Points\n",
        "        f_hat = f_hat.to(device)#to minimize function\n",
        "\n",
        "        # build PINN model\n",
        "        PINN_model = PINN(layers)\n",
        "        PINN_model.to(device)\n",
        "\n",
        "        params = list(PINN_model.parameters())\n",
        "        PINN_optimizer = torch.optim.Adam(PINN_model.parameters(),lr=lr,amsgrad=False)\n",
        "        \n",
        "        if n != 1:\n",
        "          # loading from training checkpoint\n",
        "          checkpoint = torch.load(PATH)\n",
        "          PINN_model.load_state_dict(checkpoint['model_state_dict'])\n",
        "          PINN_optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "        # Train PINN\n",
        "        trainPINN(weight_train,iter_loss,weight_train,running_loss/len(trainloader))\n",
        "        \n",
        "        # saving model checkpoint\n",
        "        PATH = 'results' + str(n) + '.pth'\n",
        "\n",
        "        torch.save({\n",
        "            'model_state_dict': PINN_model.state_dict(),\n",
        "            'optimizer_state_dict': PINN_optimizer.state_dict(),\n",
        "            }, PATH)\n",
        "        print('--------------------------SAVED PINN CHECKPOINT--------------------------')\n",
        "        print('Checkpoint #', str(n))\n",
        "          \n",
        "\n",
        "    else:\n",
        "        print(\"Epoch {} - Training loss: {}\".format(e+1, running_loss/len(trainloader)))\n",
        "print(\"\\nTraining Time (in minutes) =\",(time()-time0)/60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8GGOBLQm9vD",
        "outputId": "eeaf023f-12cd-431f-9810-0c055af9d768"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([-0.0065,  0.0633,  0.0408,  ...,  0.0657,  0.1179,  0.0986],\n",
            "       grad_fn=<ReshapeAliasBackward0>)\n",
            "8192\n"
          ]
        }
      ],
      "source": [
        "t = torch.flatten(model[2].weight)\n",
        "print(t)\n",
        "print(len(t))\n",
        "#print(model[2].weight)\n",
        "#print(len(model[2].weight))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHzVJ9FzCSQP",
        "outputId": "965b513b-3391-4489-e31a-f3942b67df92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[4. 0.]\n",
            " [4. 0.]\n",
            " [4. 0.]\n",
            " ...\n",
            " [4. 0.]\n",
            " [4. 0.]\n",
            " [4. 0.]]\n"
          ]
        }
      ],
      "source": [
        "#size testing\n",
        "import numpy as np\n",
        "\n",
        "V = np.zeros((8192,1)) + 4\n",
        "K = np.zeros((8192,1))\n",
        "Z = np.hstack((V,K))\n",
        "print(Z)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "PINN_for_MNIST_Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e2e8e1df4947410294cc1fc227701104": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_75fa7013d7dc4b758fe7e0c454954f21",
              "IPY_MODEL_5c14aad30d064e7b9897033b88de5969",
              "IPY_MODEL_bd66441f58084426965e1d8c6146f8ca"
            ],
            "layout": "IPY_MODEL_8c0fd7f2c9eb4b4ba02d4c30e3f284e0"
          }
        },
        "75fa7013d7dc4b758fe7e0c454954f21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66c8b9ab4d854c5b921dde9fa4cf83ce",
            "placeholder": "​",
            "style": "IPY_MODEL_e3c8ff45d7494d50a324c6df36b6ef92",
            "value": "100%"
          }
        },
        "5c14aad30d064e7b9897033b88de5969": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_681033c19b024a2392c42dd426a313ca",
            "max": 9912422,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5b0fb4ca031449799d4f2b8b7efcb40f",
            "value": 9912422
          }
        },
        "bd66441f58084426965e1d8c6146f8ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfbf5b82c295477b939c7862a4cc7f2b",
            "placeholder": "​",
            "style": "IPY_MODEL_e40dfcbd2722452d8e32ac876a8094f7",
            "value": " 9912422/9912422 [00:00&lt;00:00, 19855485.51it/s]"
          }
        },
        "8c0fd7f2c9eb4b4ba02d4c30e3f284e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66c8b9ab4d854c5b921dde9fa4cf83ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3c8ff45d7494d50a324c6df36b6ef92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "681033c19b024a2392c42dd426a313ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b0fb4ca031449799d4f2b8b7efcb40f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bfbf5b82c295477b939c7862a4cc7f2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e40dfcbd2722452d8e32ac876a8094f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2f22ea4d6e54e16a15e389e12befee6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_91e1516b0a884191901aae447205df44",
              "IPY_MODEL_4fb3a30bff524941b42d9dba02e7e2d5",
              "IPY_MODEL_67307813e5ea4b8b96f5177d672bdfd0"
            ],
            "layout": "IPY_MODEL_da2818d62e2a4500803ab78c693d8b68"
          }
        },
        "91e1516b0a884191901aae447205df44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09db52987c664138bca7444a658e312e",
            "placeholder": "​",
            "style": "IPY_MODEL_ac18764c015c46d8a1d8ac78feb51f3a",
            "value": "100%"
          }
        },
        "4fb3a30bff524941b42d9dba02e7e2d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76e1ac1c3ee748acbda4308b153dc181",
            "max": 28881,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_86294d4743504a23ad8a1535fc945d2a",
            "value": 28881
          }
        },
        "67307813e5ea4b8b96f5177d672bdfd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a4e54e90ab54c9b949b47309e431bca",
            "placeholder": "​",
            "style": "IPY_MODEL_3b13592dc6bf41d7b2e507c9e76f3578",
            "value": " 28881/28881 [00:00&lt;00:00, 265849.59it/s]"
          }
        },
        "da2818d62e2a4500803ab78c693d8b68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09db52987c664138bca7444a658e312e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac18764c015c46d8a1d8ac78feb51f3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76e1ac1c3ee748acbda4308b153dc181": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86294d4743504a23ad8a1535fc945d2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7a4e54e90ab54c9b949b47309e431bca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b13592dc6bf41d7b2e507c9e76f3578": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "199b0ae7aa784693bcc45dcd35cdd88b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2d0874f8443b4920b0ab54c977228c9c",
              "IPY_MODEL_10a298c255d949388d28bc5532446843",
              "IPY_MODEL_8332ffbc03204900a79e8f6da4b94197"
            ],
            "layout": "IPY_MODEL_7acaad617e4743b0b82c615ba205ef11"
          }
        },
        "2d0874f8443b4920b0ab54c977228c9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad93606885264bd6a5288ae1c46c6d58",
            "placeholder": "​",
            "style": "IPY_MODEL_b599c8b978a94170a5580a3305bfc4ee",
            "value": "100%"
          }
        },
        "10a298c255d949388d28bc5532446843": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bccdd936de36419c96030a1c50706483",
            "max": 1648877,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a1e26d5f7d894f4bbc6c26f078a35842",
            "value": 1648877
          }
        },
        "8332ffbc03204900a79e8f6da4b94197": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7a8385eeb514443ac1a5c10816110ff",
            "placeholder": "​",
            "style": "IPY_MODEL_c1d1226392ba48c3bbdad0b176778c37",
            "value": " 1648877/1648877 [00:00&lt;00:00, 6264300.05it/s]"
          }
        },
        "7acaad617e4743b0b82c615ba205ef11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad93606885264bd6a5288ae1c46c6d58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b599c8b978a94170a5580a3305bfc4ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bccdd936de36419c96030a1c50706483": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1e26d5f7d894f4bbc6c26f078a35842": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a7a8385eeb514443ac1a5c10816110ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1d1226392ba48c3bbdad0b176778c37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9a149c5013c4afe9983c5f44b5fcd42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e6c173d262834b2cb5b603fbb6c7884d",
              "IPY_MODEL_c386f522ed1a4c239df09637e76793c6",
              "IPY_MODEL_6a378cb8e16d40fc80f9440427372f93"
            ],
            "layout": "IPY_MODEL_fc78ebfacf42423884c8b16fcc471035"
          }
        },
        "e6c173d262834b2cb5b603fbb6c7884d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8a676b7b5a641f88981a8feca167a47",
            "placeholder": "​",
            "style": "IPY_MODEL_a788ed8ee53f425a9f0a53b2c5c2b9f0",
            "value": "100%"
          }
        },
        "c386f522ed1a4c239df09637e76793c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd2f64891d3247799eda26333dbe1fba",
            "max": 4542,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5e9a437837cf4ac9b348d6800eb8eb91",
            "value": 4542
          }
        },
        "6a378cb8e16d40fc80f9440427372f93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f3807f8433a4eb0aba9fd539763f2ff",
            "placeholder": "​",
            "style": "IPY_MODEL_53b82a1c141a4aa08eb05a9cedf2cee8",
            "value": " 4542/4542 [00:00&lt;00:00, 48845.88it/s]"
          }
        },
        "fc78ebfacf42423884c8b16fcc471035": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8a676b7b5a641f88981a8feca167a47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a788ed8ee53f425a9f0a53b2c5c2b9f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd2f64891d3247799eda26333dbe1fba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e9a437837cf4ac9b348d6800eb8eb91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3f3807f8433a4eb0aba9fd539763f2ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53b82a1c141a4aa08eb05a9cedf2cee8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}